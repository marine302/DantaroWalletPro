#!/usr/bin/env python3
"""
ë¦¬íŒ©í† ë§ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
ì½”ë“œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  ë¦¬íŒ©í† ë§ì´ í•„ìš”í•œ íŒŒì¼ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
"""

import ast
import json
import os
import subprocess
import sys
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


@dataclass
class FileMetrics:
    """íŒŒì¼ ë©”íŠ¸ë¦­ ì •ë³´"""

    filepath: str
    lines_of_code: int
    num_classes: int
    num_functions: int
    num_methods: int
    complexity_score: int
    max_function_length: int
    max_class_length: int
    last_modified: str
    refactoring_priority: str


class CodeMetricsAnalyzer:
    """ì½”ë“œ ë©”íŠ¸ë¦­ ë¶„ì„ê¸°"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.app_dir = self.project_root / "app"

    def analyze_file(self, filepath: Path) -> Optional[FileMetrics]:
        """ê°œë³„ íŒŒì¼ì˜ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)

            # ê¸°ë³¸ ë©”íŠ¸ë¦­
            lines_of_code = len(
                [
                    line
                    for line in content.split("\n")
                    if line.strip() and not line.strip().startswith("#")
                ]
            )

            # AST ë¶„ì„
            analyzer = ASTAnalyzer()
            analyzer.visit(tree)

            # ë³µì¡ë„ ê³„ì‚°
            complexity = self._calculate_complexity(analyzer)

            # ìˆ˜ì • ì‹œê°„
            last_modified = datetime.fromtimestamp(
                os.path.getmtime(filepath)
            ).isoformat()

            # ìš°ì„ ìˆœìœ„ ê²°ì •
            priority = self._determine_priority(lines_of_code, complexity, analyzer)

            return FileMetrics(
                filepath=str(filepath.relative_to(self.project_root)),
                lines_of_code=lines_of_code,
                num_classes=len(analyzer.classes),
                num_functions=len(analyzer.functions),
                num_methods=analyzer.total_methods,
                complexity_score=complexity,
                max_function_length=analyzer.max_function_length,
                max_class_length=analyzer.max_class_length,
                last_modified=last_modified,
                refactoring_priority=priority,
            )

        except Exception as e:
            print(f"Error analyzing {filepath}: {e}")
            return None

    def _calculate_complexity(self, analyzer) -> int:
        """ë³µì¡ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        # ê°€ì¤‘ ë³µì¡ë„ ê³„ì‚°
        base_score = analyzer.lines_of_code * 0.1
        class_penalty = len(analyzer.classes) * 5
        function_penalty = len(analyzer.functions) * 2
        method_penalty = analyzer.total_methods * 1.5
        length_penalty = max(analyzer.max_function_length - 50, 0) * 0.5

        return int(
            base_score
            + class_penalty
            + function_penalty
            + method_penalty
            + length_penalty
        )

    def _determine_priority(self, lines: int, complexity: int, analyzer) -> str:
        """ë¦¬íŒ©í† ë§ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        # ê¸´ê¸‰: 500ì¤„ ì´ìƒì´ê³  ë³µì¡ë„ ë†’ìŒ
        if lines > 500 and complexity > 100:
            return "ê¸´ê¸‰"
        # ë†’ìŒ: 300ì¤„ ì´ìƒì´ê±°ë‚˜ ë³µì¡ë„ ë†’ìŒ
        elif lines > 300 or complexity > 80:
            return "ë†’ìŒ"
        # ì¤‘ê°„: 200ì¤„ ì´ìƒì´ê±°ë‚˜ ë©”ì„œë“œ ë§ìŒ
        elif lines > 200 or analyzer.total_methods > 15:
            return "ì¤‘ê°„"
        # ë‚®ìŒ: ê·¸ ì™¸
        else:
            return "ë‚®ìŒ"

    def analyze_project(self) -> List[FileMetrics]:
        """í”„ë¡œì íŠ¸ ì „ì²´ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        metrics = []

        # Python íŒŒì¼ ì°¾ê¸°
        for py_file in self.app_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or py_file.name.startswith("test_"):
                continue

            file_metrics = self.analyze_file(py_file)
            if file_metrics:
                metrics.append(file_metrics)

        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬
        priority_order = {"ê¸´ê¸‰": 0, "ë†’ìŒ": 1, "ì¤‘ê°„": 2, "ë‚®ìŒ": 3}
        metrics.sort(
            key=lambda x: (priority_order[x.refactoring_priority], -x.lines_of_code)
        )

        return metrics

    def generate_report(self, metrics: List[FileMetrics]) -> str:
        """ë¦¬íŒ©í† ë§ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        report = []
        report.append("# ğŸ“Š ì½”ë“œ ë©”íŠ¸ë¦­ ë° ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ")
        report.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # ìš”ì•½ í†µê³„
        total_files = len(metrics)
        urgent_files = len([m for m in metrics if m.refactoring_priority == "ê¸´ê¸‰"])
        high_files = len([m for m in metrics if m.refactoring_priority == "ë†’ìŒ"])

        report.append("## ğŸ“ˆ ìš”ì•½ í†µê³„")
        report.append(f"- ì „ì²´ ë¶„ì„ íŒŒì¼: {total_files}ê°œ")
        report.append(f"- ê¸´ê¸‰ ë¦¬íŒ©í† ë§ í•„ìš”: {urgent_files}ê°œ")
        report.append(f"- ë†’ì€ ìš°ì„ ìˆœìœ„: {high_files}ê°œ")
        report.append("")

        # ìš°ì„ ìˆœìœ„ë³„ íŒŒì¼ ëª©ë¡
        for priority in ["ê¸´ê¸‰", "ë†’ìŒ", "ì¤‘ê°„"]:
            priority_files = [m for m in metrics if m.refactoring_priority == priority]
            if not priority_files:
                continue

            report.append(f"## ğŸ”´ {priority} ìš°ì„ ìˆœìœ„ íŒŒì¼")
            report.append("")

            for metric in priority_files:
                report.append(f"### {metric.filepath}")
                report.append(f"- ì½”ë“œ ë¼ì¸: {metric.lines_of_code}")
                report.append(f"- í´ë˜ìŠ¤ ìˆ˜: {metric.num_classes}")
                report.append(f"- í•¨ìˆ˜ ìˆ˜: {metric.num_functions}")
                report.append(f"- ë©”ì„œë“œ ìˆ˜: {metric.num_methods}")
                report.append(f"- ë³µì¡ë„ ì ìˆ˜: {metric.complexity_score}")
                report.append(f"- ìµœëŒ€ í•¨ìˆ˜ ê¸¸ì´: {metric.max_function_length}")
                report.append("")

        return "\n".join(report)


class ASTAnalyzer(ast.NodeVisitor):
    """AST ë…¸ë“œ ë°©ë¬¸ì"""

    def __init__(self):
        self.classes = []
        self.functions = []
        self.methods = []
        self.total_methods = 0
        self.max_function_length = 0
        self.max_class_length = 0
        self.lines_of_code = 0
        self.current_class = None

    def visit_ClassDef(self, node):
        """í´ë˜ìŠ¤ ì •ì˜ ë°©ë¬¸"""
        self.classes.append(
            {
                "name": node.name,
                "lineno": node.lineno,
                "end_lineno": getattr(node, "end_lineno", node.lineno),
            }
        )

        class_length = getattr(node, "end_lineno", node.lineno) - node.lineno + 1
        self.max_class_length = max(self.max_class_length, class_length)

        self.current_class = node.name
        self.generic_visit(node)
        self.current_class = None

    def visit_FunctionDef(self, node):
        """í•¨ìˆ˜ ì •ì˜ ë°©ë¬¸"""
        func_info = {
            "name": node.name,
            "lineno": node.lineno,
            "end_lineno": getattr(node, "end_lineno", node.lineno),
            "class": self.current_class,
        }

        if self.current_class:
            self.methods.append(func_info)
            self.total_methods += 1
        else:
            self.functions.append(func_info)

        func_length = getattr(node, "end_lineno", node.lineno) - node.lineno + 1
        self.max_function_length = max(self.max_function_length, func_length)

        self.generic_visit(node)


class RefactoringPlanner:
    """ë¦¬íŒ©í† ë§ ê³„íš ìƒì„±ê¸°"""

    def __init__(self, metrics: List[FileMetrics]):
        self.metrics = metrics

    def generate_action_plan(self) -> Dict[str, Any]:
        """ë¦¬íŒ©í† ë§ ì•¡ì…˜ í”Œëœì„ ìƒì„±í•©ë‹ˆë‹¤."""
        plan = {
            "immediate_actions": [],
            "short_term_goals": [],
            "long_term_goals": [],
            "automation_recommendations": [],
        }

        # ê¸´ê¸‰ ì•¡ì…˜
        urgent_files = [m for m in self.metrics if m.refactoring_priority == "ê¸´ê¸‰"]
        for file_metric in urgent_files:
            plan["immediate_actions"].append(
                {
                    "file": file_metric.filepath,
                    "action": "ëª¨ë“ˆ ë¶„í•´",
                    "reason": f"ì½”ë“œ ë¼ì¸ {file_metric.lines_of_code}, ë³µì¡ë„ {file_metric.complexity_score}",
                    "estimated_effort": "ë†’ìŒ",
                }
            )

        # ë‹¨ê¸° ëª©í‘œ
        high_files = [m for m in self.metrics if m.refactoring_priority == "ë†’ìŒ"]
        for file_metric in high_files:
            plan["short_term_goals"].append(
                {
                    "file": file_metric.filepath,
                    "action": "í•¨ìˆ˜ ë¶„ë¦¬ ë° í´ë˜ìŠ¤ ë¦¬íŒ©í† ë§",
                    "reason": f"ì½”ë“œ ë¼ì¸ {file_metric.lines_of_code}",
                    "estimated_effort": "ì¤‘ê°„",
                }
            )

        # ì¥ê¸° ëª©í‘œ
        plan["long_term_goals"].extend(
            ["ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„ íŒ¨í„´ ì ìš©", "ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬ ë° ì˜ì¡´ì„± ì£¼ì…", "ì•„í‚¤í…ì²˜ ê³„ì¸µ ë¶„ë¦¬"]
        )

        # ìë™í™” ê¶Œê³ ì‚¬í•­
        plan["automation_recommendations"].extend(
            [
                "pre-commit hook ì„¤ì •ìœ¼ë¡œ ì½”ë“œ í’ˆì§ˆ ìë™ ê²€ì‚¬",
                "CI/CD íŒŒì´í”„ë¼ì¸ì— ë©”íŠ¸ë¦­ ì²´í¬ ì¶”ê°€",
                "ì •ê¸°ì ì¸ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„± ìë™í™”",
            ]
        )

        return plan


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) > 1:
        project_root = sys.argv[1]
    else:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    analyzer = CodeMetricsAnalyzer(project_root)
    metrics = analyzer.analyze_project()

    # ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_report(metrics)

    # ì•¡ì…˜ í”Œëœ ìƒì„±
    planner = RefactoringPlanner(metrics)
    action_plan = planner.generate_action_plan()

    # ê²°ê³¼ ì €ì¥
    docs_dir = Path(project_root) / "docs"
    docs_dir.mkdir(exist_ok=True)

    # ë³´ê³ ì„œ íŒŒì¼
    with open(docs_dir / "CODE_METRICS_REPORT.md", "w", encoding="utf-8") as f:
        f.write(report)

    # ë©”íŠ¸ë¦­ JSON
    with open(docs_dir / "code_metrics.json", "w", encoding="utf-8") as f:
        json.dump([asdict(m) for m in metrics], f, indent=2, ensure_ascii=False)

    # ì•¡ì…˜ í”Œëœ JSON
    with open(docs_dir / "refactoring_action_plan.json", "w", encoding="utf-8") as f:
        json.dump(action_plan, f, indent=2, ensure_ascii=False)

    print(f"âœ… ë¦¬íŒ©í† ë§ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"ğŸ“Š ë©”íŠ¸ë¦­ ë³´ê³ ì„œ: {docs_dir / 'CODE_METRICS_REPORT.md'}")
    print(f"ğŸ“ˆ ë©”íŠ¸ë¦­ ë°ì´í„°: {docs_dir / 'code_metrics.json'}")
    print(f"ğŸ“‹ ì•¡ì…˜ í”Œëœ: {docs_dir / 'refactoring_action_plan.json'}")


if __name__ == "__main__":
    main()
