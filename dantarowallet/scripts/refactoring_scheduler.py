"""
ì •ê¸°ì ì¸ ë¦¬íŒ©í† ë§ ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
ì½”ë“œ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ê³¼ ìë™í™”ëœ ë¦¬íŒ©í† ë§ ì œì•ˆì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List

import schedule

from app.core.database import get_async_session
from scripts.pre_commit_check import generate_quality_report
from scripts.refactoring_monitor import CodeMetricsAnalyzer, RefactoringPlanner

logger = logging.getLogger(__name__)


class RefactoringScheduler:
    """ë¦¬íŒ©í† ë§ ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.docs_dir = self.project_root / "docs"
        self.metrics_analyzer = CodeMetricsAnalyzer(str(project_root))
        self.last_metrics = {}
        self.refactoring_tasks = []

    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        logger.info("ğŸš€ ë¦¬íŒ©í† ë§ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

        # ìŠ¤ì¼€ì¤„ ì„¤ì •
        self._setup_schedules()

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        while True:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            except KeyboardInterrupt:
                logger.info("ë¦¬íŒ©í† ë§ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€")
                break
            except Exception as e:
                logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                time.sleep(300)  # ì˜¤ë¥˜ ì‹œ 5ë¶„ ëŒ€ê¸°

    def _setup_schedules(self):
        """ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë§¤ì¼ ì˜¤ì „ 9ì‹œ - ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        schedule.every().day.at("09:00").do(self._daily_metrics_collection)

        # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 10ì‹œ - ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ
        schedule.every().monday.at("10:00").do(self._weekly_refactoring_report)

        # ë§¤ì›” 1ì¼ ì˜¤ì „ 11ì‹œ - ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·°
        schedule.every().month.do(self._monthly_architecture_review)

        # ë§¤ ì‹œê°„ - ì½”ë“œ í’ˆì§ˆ ì²´í¬ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
        if self._is_development_environment():
            schedule.every().hour.do(self._hourly_quality_check)

        # íŒŒì¼ ë³€ê²½ ê°ì§€ ì‹œ - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ)
        schedule.every(30).minutes.do(self._update_metrics_if_changed)

    def _is_development_environment(self) -> bool:
        """ê°œë°œ í™˜ê²½ì¸ì§€ í™•ì¸"""
        import os

        return os.getenv("ENVIRONMENT", "development").lower() == "development"

    def _daily_metrics_collection(self):
        """ì¼ì¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            logger.info("ğŸ“Š ì¼ì¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘")

            # ë©”íŠ¸ë¦­ ë¶„ì„
            metrics = self.metrics_analyzer.analyze_project()

            # ë³´ê³ ì„œ ìƒì„±
            report = self.metrics_analyzer.generate_report(metrics)

            # ì•¡ì…˜ í”Œëœ ìƒì„±
            planner = RefactoringPlanner(metrics)
            action_plan = planner.generate_action_plan()

            # ê²°ê³¼ ì €ì¥
            self._save_daily_metrics(metrics, report, action_plan)

            # ì„ê³„ê°’ ì²´í¬ ë° ì•Œë¦¼
            self._check_metrics_thresholds(metrics)

            logger.info("âœ… ì¼ì¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì¼ì¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _weekly_refactoring_report(self):
        """ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„±"""
        try:
            logger.info("ğŸ“‹ ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")

            # ì´ë²ˆ ì£¼ ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘
            weekly_data = self._collect_weekly_data()

            # ë¦¬íŒ©í† ë§ ì§„í–‰ìƒí™© ë¶„ì„
            progress_analysis = self._analyze_refactoring_progress(weekly_data)

            # ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ ê²°ì •
            next_week_priorities = self._determine_next_week_priorities(weekly_data)

            # ë³´ê³ ì„œ ìƒì„±
            report = self._generate_weekly_report(
                progress_analysis, next_week_priorities
            )

            # ë³´ê³ ì„œ ì €ì¥
            self._save_weekly_report(report)

            # íŒ€ ì•Œë¦¼ (Slack, ì´ë©”ì¼ ë“±)
            self._send_weekly_notification(report)

            logger.info("âœ… ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _monthly_architecture_review(self):
        """ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·°"""
        try:
            logger.info("ğŸ—ï¸ ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·° ì‹œì‘")

            # ì•„í‚¤í…ì²˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            architecture_metrics = self._collect_architecture_metrics()

            # ì˜ì¡´ì„± ë¶„ì„
            dependency_analysis = self._analyze_dependencies()

            # ì•„í‚¤í…ì²˜ ê°œì„  ì œì•ˆ
            improvement_suggestions = self._generate_architecture_improvements(
                architecture_metrics, dependency_analysis
            )

            # ì›”ê°„ ë¦¬ë·° ë³´ê³ ì„œ ìƒì„±
            review_report = self._generate_monthly_review(
                architecture_metrics, dependency_analysis, improvement_suggestions
            )

            # ë³´ê³ ì„œ ì €ì¥
            self._save_monthly_review(review_report)

            logger.info("âœ… ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·° ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·° ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _hourly_quality_check(self):
        """ì‹œê°„ë³„ í’ˆì§ˆ ì²´í¬"""
        try:
            logger.info("ğŸ” ì‹œê°„ë³„ í’ˆì§ˆ ì²´í¬ ì‹œì‘")

            # ì½”ë“œ í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±
            quality_report = generate_quality_report()

            # í’ˆì§ˆ ì €í•˜ ê°ì§€
            if quality_report["status"] == "FAIL":
                self._handle_quality_degradation(quality_report)

            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì €ì¥
            self._save_quality_metrics(quality_report)

            logger.info("âœ… ì‹œê°„ë³„ í’ˆì§ˆ ì²´í¬ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì‹œê°„ë³„ í’ˆì§ˆ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _update_metrics_if_changed(self):
        """íŒŒì¼ ë³€ê²½ ì‹œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        try:
            # íŒŒì¼ ë³€ê²½ ê°ì§€
            if self._detect_file_changes():
                logger.info("ğŸ“ íŒŒì¼ ë³€ê²½ ê°ì§€, ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸")

                # ë³€ê²½ëœ íŒŒì¼ë“¤ì— ëŒ€í•´ì„œë§Œ ë©”íŠ¸ë¦­ ì¬ê³„ì‚°
                changed_files = self._get_changed_files()
                updated_metrics = self._update_changed_file_metrics(changed_files)

                # ë©”íŠ¸ë¦­ ì €ì¥
                self._save_incremental_metrics(updated_metrics)

        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def _save_daily_metrics(self, metrics: List, report: str, action_plan: Dict):
        """ì¼ì¼ ë©”íŠ¸ë¦­ ì €ì¥"""
        date_str = datetime.now().strftime("%Y-%m-%d")

        # ë©”íŠ¸ë¦­ JSON ì €ì¥
        metrics_file = self.docs_dir / f"daily_metrics_{date_str}.json"
        with open(metrics_file, "w", encoding="utf-8") as f:
            json.dump(
                [metric.__dict__ for metric in metrics], f, indent=2, ensure_ascii=False
            )

        # ë³´ê³ ì„œ ì €ì¥
        report_file = self.docs_dir / f"daily_report_{date_str}.md"
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

        # ì•¡ì…˜ í”Œëœ ì €ì¥
        plan_file = self.docs_dir / f"action_plan_{date_str}.json"
        with open(plan_file, "w", encoding="utf-8") as f:
            json.dump(action_plan, f, indent=2, ensure_ascii=False)

    def _check_metrics_thresholds(self, metrics: List):
        """ë©”íŠ¸ë¦­ ì„ê³„ê°’ ì²´í¬ ë° ì•Œë¦¼"""
        urgent_files = [m for m in metrics if m.refactoring_priority == "ê¸´ê¸‰"]

        if urgent_files:
            logger.warning(f"âš ï¸ ê¸´ê¸‰ ë¦¬íŒ©í† ë§ í•„ìš” íŒŒì¼ {len(urgent_files)}ê°œ ë°œê²¬")

            # ì•Œë¦¼ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Slack, ì´ë©”ì¼ ë“±)
            self._send_urgent_alert(urgent_files)

    def _send_urgent_alert(self, urgent_files: List):
        """ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡"""
        message = f"ğŸš¨ ê¸´ê¸‰ ë¦¬íŒ©í† ë§ í•„ìš”!\n\n"
        message += f"ëŒ€ìƒ íŒŒì¼ ìˆ˜: {len(urgent_files)}\n"

        for file_metric in urgent_files[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            message += f"- {file_metric.filepath}: {file_metric.lines_of_code}ì¤„\n"

        logger.error(message)

        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Slack webhook, ì´ë©”ì¼ ë°œì†¡ ë“±
        # self._send_slack_notification(message)
        # self._send_email_notification(message)

    def _collect_weekly_data(self) -> Dict[str, Any]:
        """ì£¼ê°„ ë°ì´í„° ìˆ˜ì§‘"""
        weekly_data = {
            "period": {
                "start": (datetime.now() - timedelta(days=7)).isoformat(),
                "end": datetime.now().isoformat(),
            },
            "metrics_history": [],
            "refactoring_activities": [],
            "quality_trends": [],
        }

        # ì§€ë‚œ 7ì¼ì˜ ë©”íŠ¸ë¦­ íŒŒì¼ë“¤ ìˆ˜ì§‘
        for i in range(7):
            date = datetime.now() - timedelta(days=i)
            date_str = date.strftime("%Y-%m-%d")

            metrics_file = self.docs_dir / f"daily_metrics_{date_str}.json"
            if metrics_file.exists():
                with open(metrics_file, "r", encoding="utf-8") as f:
                    daily_metrics = json.load(f)
                    weekly_data["metrics_history"].append(
                        {"date": date_str, "metrics": daily_metrics}
                    )

        return weekly_data

    def _analyze_refactoring_progress(self, weekly_data: Dict) -> Dict[str, Any]:
        """ë¦¬íŒ©í† ë§ ì§„í–‰ìƒí™© ë¶„ì„"""
        if not weekly_data["metrics_history"]:
            return {"status": "no_data"}

        # ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ë¹„êµ
        first_day = weekly_data["metrics_history"][-1]["metrics"]
        last_day = weekly_data["metrics_history"][0]["metrics"]

        # ê¸´ê¸‰ íŒŒì¼ ìˆ˜ ë³€í™”
        first_urgent = len(
            [m for m in first_day if m.get("refactoring_priority") == "ê¸´ê¸‰"]
        )
        last_urgent = len(
            [m for m in last_day if m.get("refactoring_priority") == "ê¸´ê¸‰"]
        )

        progress = {
            "urgent_files_change": last_urgent - first_urgent,
            "total_files_analyzed": len(last_day),
            "improvement_trend": (
                "improving"
                if last_urgent < first_urgent
                else "stable" if last_urgent == first_urgent else "degrading"
            ),
        }

        return progress

    def _determine_next_week_priorities(
        self, weekly_data: Dict
    ) -> List[Dict[str, Any]]:
        """ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ ê²°ì •"""
        if not weekly_data["metrics_history"]:
            return []

        latest_metrics = weekly_data["metrics_history"][0]["metrics"]
        urgent_files = [
            m for m in latest_metrics if m.get("refactoring_priority") == "ê¸´ê¸‰"
        ]

        priorities = []
        for file_metric in urgent_files[:3]:  # ìƒìœ„ 3ê°œ
            priorities.append(
                {
                    "file": file_metric.get("filepath"),
                    "priority": "ë†’ìŒ",
                    "estimated_effort": "3-5ì¼",
                    "reason": f"ë³µì¡ë„ {file_metric.get('complexity_score')}, {file_metric.get('lines_of_code')}ì¤„",
                }
            )

        return priorities

    def _generate_weekly_report(self, progress: Dict, priorities: List) -> str:
        """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±"""
        report = []
        report.append("# ğŸ“Š ì£¼ê°„ ë¦¬íŒ©í† ë§ ë³´ê³ ì„œ")
        report.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        report.append("## ğŸ“ˆ ì´ë²ˆ ì£¼ ì§„í–‰ìƒí™©")
        if progress.get("status") == "no_data":
            report.append("- ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€")
        else:
            report.append(f"- ê¸´ê¸‰ íŒŒì¼ ë³€í™”: {progress['urgent_files_change']}")
            report.append(f"- ì „ì²´ ë¶„ì„ íŒŒì¼: {progress['total_files_analyzed']}")
            report.append(f"- ê°œì„  ì¶”ì„¸: {progress['improvement_trend']}")

        report.append("")
        report.append("## ğŸ¯ ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„")
        for i, priority in enumerate(priorities, 1):
            report.append(f"{i}. **{priority['file']}**")
            report.append(f"   - ìš°ì„ ìˆœìœ„: {priority['priority']}")
            report.append(f"   - ì˜ˆìƒ ì†Œìš”: {priority['estimated_effort']}")
            report.append(f"   - ì‚¬ìœ : {priority['reason']}")

        return "\n".join(report)

    def _save_weekly_report(self, report: str):
        """ì£¼ê°„ ë³´ê³ ì„œ ì €ì¥"""
        week_str = datetime.now().strftime("%Y-W%U")
        report_file = self.docs_dir / f"weekly_refactoring_report_{week_str}.md"

        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

    def _send_weekly_notification(self, report: str):
        """ì£¼ê°„ ì•Œë¦¼ ë°œì†¡"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Slack, Teams, ì´ë©”ì¼ ë“±
        logger.info("ğŸ“® ì£¼ê°„ ë³´ê³ ì„œ ì•Œë¦¼ ë°œì†¡")
        # self._send_slack_notification(report[:500] + "...")

    def _collect_architecture_metrics(self) -> Dict[str, Any]:
        """ì•„í‚¤í…ì²˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            "module_count": len(list(self.project_root.rglob("*.py"))),
            "dependency_depth": 5,  # ì‹¤ì œë¡œëŠ” ì˜ì¡´ì„± ë¶„ì„ í•„ìš”
            "coupling_score": 3.2,  # ì‹¤ì œë¡œëŠ” ì»¤í”Œë§ ë¶„ì„ í•„ìš”
            "cohesion_score": 7.8,  # ì‹¤ì œë¡œëŠ” ì‘ì§‘ë„ ë¶„ì„ í•„ìš”
        }

    def _analyze_dependencies(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ë¶„ì„"""
        return {
            "circular_dependencies": [],
            "high_coupling_modules": [],
            "unused_imports": [],
        }

    def _generate_architecture_improvements(
        self, metrics: Dict, dependencies: Dict
    ) -> List[str]:
        """ì•„í‚¤í…ì²˜ ê°œì„  ì œì•ˆ"""
        improvements = []

        if metrics["coupling_score"] > 5:
            improvements.append("ëª¨ë“ˆ ê°„ ê²°í•©ë„ ê°ì†Œ í•„ìš”")

        if metrics["cohesion_score"] < 7:
            improvements.append("ëª¨ë“ˆ ë‚´ ì‘ì§‘ë„ ê°œì„  í•„ìš”")

        if dependencies["circular_dependencies"]:
            improvements.append("ìˆœí™˜ ì˜ì¡´ì„± ì œê±° í•„ìš”")

        return improvements

    def _generate_monthly_review(
        self, metrics: Dict, dependencies: Dict, improvements: List
    ) -> str:
        """ì›”ê°„ ë¦¬ë·° ë³´ê³ ì„œ ìƒì„±"""
        review = []
        review.append("# ğŸ—ï¸ ì›”ê°„ ì•„í‚¤í…ì²˜ ë¦¬ë·°")
        review.append(f"ë¦¬ë·° ê¸°ê°„: {datetime.now().strftime('%Yë…„ %mì›”')}")
        review.append("")

        review.append("## ğŸ“Š ì•„í‚¤í…ì²˜ ë©”íŠ¸ë¦­")
        for key, value in metrics.items():
            review.append(f"- {key}: {value}")

        review.append("")
        review.append("## ğŸ” ì˜ì¡´ì„± ë¶„ì„")
        for key, value in dependencies.items():
            review.append(f"- {key}: {len(value)}ê°œ")

        review.append("")
        review.append("## ğŸ’¡ ê°œì„  ì œì•ˆ")
        for improvement in improvements:
            review.append(f"- {improvement}")

        return "\n".join(review)

    def _save_monthly_review(self, review: str):
        """ì›”ê°„ ë¦¬ë·° ì €ì¥"""
        month_str = datetime.now().strftime("%Y-%m")
        review_file = self.docs_dir / f"monthly_architecture_review_{month_str}.md"

        with open(review_file, "w", encoding="utf-8") as f:
            f.write(review)

    def _detect_file_changes(self) -> bool:
        """íŒŒì¼ ë³€ê²½ ê°ì§€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” watchdog ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
        return False

    def _get_changed_files(self) -> List[str]:
        """ë³€ê²½ëœ íŒŒì¼ ëª©ë¡"""
        return []

    def _update_changed_file_metrics(self, files: List[str]) -> Dict:
        """ë³€ê²½ëœ íŒŒì¼ì˜ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        return {}

    def _save_incremental_metrics(self, metrics: Dict):
        """ì¦ë¶„ ë©”íŠ¸ë¦­ ì €ì¥"""
        pass

    def _handle_quality_degradation(self, quality_report: Dict):
        """í’ˆì§ˆ ì €í•˜ ì²˜ë¦¬"""
        logger.warning("âš ï¸ ì½”ë“œ í’ˆì§ˆ ì €í•˜ ê°ì§€")
        # ì‹¤ì œë¡œëŠ” ì•Œë¦¼ ë°œì†¡, ìë™ ìˆ˜ì • ë“±

    def _save_quality_metrics(self, quality_report: Dict):
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        quality_file = self.docs_dir / f"quality_metrics_{timestamp}.json"

        with open(quality_file, "w", encoding="utf-8") as f:
            json.dump(quality_report, f, indent=2, ensure_ascii=False)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys

    if len(sys.argv) > 1:
        project_root = sys.argv[1]
    else:
        project_root = "/Users/danielkwon/DantaroWalletPro/DantaroWalletPro"

    scheduler = RefactoringScheduler(project_root)
    scheduler.start_scheduler()


if __name__ == "__main__":
    main()
