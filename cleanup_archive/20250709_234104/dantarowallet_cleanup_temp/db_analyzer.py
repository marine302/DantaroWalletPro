#!/usr/bin/env python3
"""
DantaroWallet ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ê¸°
í˜„ì¬ ì‹œìŠ¤í…œì˜ ëª¨ë“  í…Œì´ë¸”, ì»¬ëŸ¼, ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ERDì™€ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import sqlite3
import json
from datetime import datetime
import os

def analyze_database():
    """ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    db_path = 'dev.db'
    if not os.path.exists(db_path):
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        return None
    
    print("ğŸ” DantaroWallet ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„")
    print("=" * 60)
    print(f"ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ë°ì´í„°ë² ì´ìŠ¤: {db_path}")
    print()
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. ëª¨ë“  í…Œì´ë¸” ì¡°íšŒ
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = [row[0] for row in cursor.fetchall()]
        
        print(f"ğŸ“Š ì´ {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        print("-" * 40)
        
        db_schema = {
            "database_name": "DantaroWallet",
            "analyzed_at": datetime.now().isoformat(),
            "total_tables": len(tables),
            "tables": {}
        }
        
        # 2. ê° í…Œì´ë¸”ì˜ êµ¬ì¡° ë¶„ì„
        for table_name in tables:
            print(f"\nğŸ”¸ í…Œì´ë¸”: {table_name}")
            
            # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = cursor.fetchall()
            
            # ì™¸ë˜í‚¤ ì¡°íšŒ
            cursor.execute(f"PRAGMA foreign_key_list({table_name});")
            foreign_keys = cursor.fetchall()
            
            # ì¸ë±ìŠ¤ ì¡°íšŒ
            cursor.execute(f"PRAGMA index_list({table_name});")
            indexes = cursor.fetchall()
            
            table_info = {
                "name": table_name,
                "columns": [],
                "foreign_keys": [],
                "indexes": [],
                "row_count": 0
            }
            
            # ì»¬ëŸ¼ ì •ë³´ ì²˜ë¦¬
            for col in columns:
                col_info = {
                    "name": col[1],
                    "type": col[2],
                    "not_null": bool(col[3]),
                    "default_value": col[4],
                    "primary_key": bool(col[5])
                }
                table_info["columns"].append(col_info)
                print(f"  ğŸ“‹ {col[1]}: {col[2]} {'PK' if col[5] else ''} {'NOT NULL' if col[3] else ''}")
            
            # ì™¸ë˜í‚¤ ì •ë³´ ì²˜ë¦¬
            for fk in foreign_keys:
                fk_info = {
                    "column": fk[3],
                    "referenced_table": fk[2],
                    "referenced_column": fk[4]
                }
                table_info["foreign_keys"].append(fk_info)
                print(f"  ğŸ”— FK: {fk[3]} -> {fk[2]}.{fk[4]}")
            
            # ì¸ë±ìŠ¤ ì •ë³´ ì²˜ë¦¬
            for idx in indexes:
                table_info["indexes"].append({
                    "name": idx[1],
                    "unique": bool(idx[2])
                })
            
            # í–‰ ê°œìˆ˜ ì¡°íšŒ
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
                table_info["row_count"] = cursor.fetchone()[0]
                print(f"  ğŸ“Š í–‰ ê°œìˆ˜: {table_info['row_count']}")
            except:
                print(f"  ğŸ“Š í–‰ ê°œìˆ˜: ì¡°íšŒ ë¶ˆê°€")
            
            db_schema["tables"][table_name] = table_info
        
        conn.close()
        return db_schema
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def generate_schema_document(schema):
    """ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    if not schema:
        return
    
    doc_content = f"""# DantaroWallet ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ

## ğŸ“Š ê¸°ë³¸ ì •ë³´
- **ë°ì´í„°ë² ì´ìŠ¤ëª…**: {schema['database_name']}
- **ë¶„ì„ ì¼ì‹œ**: {schema['analyzed_at']}
- **ì´ í…Œì´ë¸” ìˆ˜**: {schema['total_tables']}

## ğŸ“‹ í…Œì´ë¸” ëª©ë¡

"""
    
    # í…Œì´ë¸”ë³„ ìƒì„¸ ì •ë³´
    for table_name, table_info in schema["tables"].items():
        doc_content += f"""### {table_name}
- **í–‰ ê°œìˆ˜**: {table_info['row_count']}
- **ì»¬ëŸ¼ ìˆ˜**: {len(table_info['columns'])}

#### ì»¬ëŸ¼ êµ¬ì¡°
| ì»¬ëŸ¼ëª… | íƒ€ì… | PK | Not Null | ê¸°ë³¸ê°’ |
|--------|------|----| ---------|--------|
"""
        
        for col in table_info["columns"]:
            pk = "âœ…" if col["primary_key"] else ""
            not_null = "âœ…" if col["not_null"] else ""
            default = col["default_value"] if col["default_value"] else ""
            doc_content += f"| {col['name']} | {col['type']} | {pk} | {not_null} | {default} |\n"
        
        # ì™¸ë˜í‚¤ ì •ë³´
        if table_info["foreign_keys"]:
            doc_content += "\n#### ì™¸ë˜í‚¤\n"
            for fk in table_info["foreign_keys"]:
                doc_content += f"- `{fk['column']}` â†’ `{fk['referenced_table']}.{fk['referenced_column']}`\n"
        
        # ì¸ë±ìŠ¤ ì •ë³´
        if table_info["indexes"]:
            doc_content += "\n#### ì¸ë±ìŠ¤\n"
            for idx in table_info["indexes"]:
                unique = "UNIQUE" if idx["unique"] else ""
                doc_content += f"- `{idx['name']}` {unique}\n"
        
        doc_content += "\n---\n\n"
    
    # íŒŒì¼ ì €ì¥
    with open("DATABASE_SCHEMA.md", "w", encoding="utf-8") as f:
        f.write(doc_content)
    
    # JSON íŒŒì¼ë¡œë„ ì €ì¥
    with open("database_schema.json", "w", encoding="utf-8") as f:
        json.dump(schema, f, indent=2, ensure_ascii=False)
    
    print("\nâœ… ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ìƒì„± ì™„ë£Œ:")
    print("ğŸ“„ DATABASE_SCHEMA.md - ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ")
    print("ğŸ“„ database_schema.json - JSON ìŠ¤í‚¤ë§ˆ íŒŒì¼")

if __name__ == "__main__":
    schema = analyze_database()
    if schema:
        generate_schema_document(schema)
    else:
        print("âŒ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì‹¤íŒ¨")
